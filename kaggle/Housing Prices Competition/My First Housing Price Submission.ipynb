{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nIn this notebook, i will take you through the step by step approach in solving a House Pricing regression problem. This notebook aims to:\n\n1. Provide insights on Housing Data\n2. Understand importance of Preprocessing\n3. Introduction to feature engineering\n4. Use of ensembling algorithm\n\nI hope that after reading this notebook, beginners will be more comfortable in tackling any learning problems and able to use the taught techniques to solve any problems from start to end. For non-beginners, hopefully you are able to get something out of it from this notebook and gain new insights and knowledge along the way :)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style(\"darkgrid\")\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.impute import SimpleImputer\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(font_scale=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing data from csv file using pandas\ntrain=pd.read_csv('../input/home-data-for-ml-course/train.csv')\ntest=pd.read_csv('../input/home-data-for-ml-course/test.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Understanding Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train\",train.shape)\nprint(\"Test\",test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just taking a quick glance at the top rows of the dataframe, we can see that there are some columns that are filled with **NAN (Not a Number)**. We will investigate this later on.\n\nWhat i did here is first to concatenate the train and test together for extracting insights into the Housing Price data as a whole. It will also be more convenient for our preprocessing steps later on as we will only have 1 data reference","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.concat([train.drop(\"SalePrice\", axis=1),test], axis=0)\ny = train[['SalePrice']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets isolate both the numerical and categorical columns since we will be applying different visualization techniques on them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_ = X.select_dtypes(exclude=['object']).drop(['MSSubClass'], axis=1).copy()\nnumeric_.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_train = X.select_dtypes(include=['object']).copy()\ncat_train['MSSubClass'] = X['MSSubClass']   #MSSubClass is nominal\ncat_train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.Data Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets create scatterplot of GrLivArea and SalePrice\nsns.scatterplot(x='GrLivArea',y='SalePrice',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#as per above plot we can see there are two outliers which can affect on out model,lets remove those outliers\ntrain=train.drop(train.loc[(train['GrLivArea']>4000) & (train['SalePrice']<200000)].index,0)\ntrain.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lest we how its look after removing outliers\nsns.scatterplot(x='GrLivArea',y='SalePrice',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets create heatmap first of all lest see on which feature SalePrice is dependent\ncorr=train.drop('Id',1).corr().sort_values(by='SalePrice',ascending=False).round(2)\nprint(corr['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here we can see SalePrice mostly dependent on this features OverallQual,GrLivArea,TotalBsmtSF,GarageCars,1stFlrSF,GarageArea \nplt.subplots(figsize=(12, 9))\nsns.heatmap(corr, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now lets create heatmap for top 10 correlated features\ncols =corr['SalePrice'].head(10).index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1)\nhm = sns.heatmap(cm, annot=True, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see relation of 10 feature with SalePrice through Pairplot\nsns.pairplot(train[corr['SalePrice'].head(10).index])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extra Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets store number of test and train rows\ntrainrow=train.shape[0]\ntestrow=test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#copying id data\ntestids=test['Id'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#copying sales priece\ny_train=train['SalePrice'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining train and test data\ndata=pd.concat((train,test)).reset_index(drop=True)\ndata=data.drop('SalePrice',1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping id columns\ndata=data.drop('Id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing Value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking missing data\nmissing=data.isnull().sum().sort_values(ascending=False)\nmissing=missing.drop(missing[missing==0].index)\nmissing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PoolQC is quality of pool but mostly house does not have pool so putting NA\ndata['PoolQC']=data['PoolQC'].fillna('NA')\ndata['PoolQC'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MiscFeature: mostly house does not have it so putting NA\ndata['MiscFeature']=data['MiscFeature'].fillna('NA')\ndata['MiscFeature'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Alley,Fence,FireplaceQu: mostly house does not have it so putting NA\ndata['Alley']=data['Alley'].fillna('NA')\ndata['Alley'].unique()\n\ndata['Fence']=data['Fence'].fillna('NA')\ndata['Fence'].unique()\n\ndata['FireplaceQu']=data['FireplaceQu'].fillna('NA')\ndata['FireplaceQu'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LotFrontage: all house have linear connected feet so putting most mean value\ndata['LotFrontage']=data['LotFrontage'].fillna(data['LotFrontage'].dropna().mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GarageCond,GarageQual,GarageFinish\ndata['GarageCond']=data['GarageCond'].fillna('NA')\ndata['GarageCond'].unique()\n\ndata['GarageQual']=data['GarageQual'].fillna('NA')\ndata['GarageQual'].unique()\n\ndata['GarageFinish']=data['GarageFinish'].fillna('NA')\ndata['GarageFinish'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GarageYrBlt,GarageType,GarageArea,GarageCars putting 0\ndata['GarageYrBlt']=data['GarageYrBlt'].fillna(0)\ndata['GarageType']=data['GarageType'].fillna(0)\ndata['GarageArea']=data['GarageArea'].fillna(0)\ndata['GarageCars']=data['GarageCars'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#BsmtExposure,BsmtCond,BsmtQual,BsmtFinType2,BsmtFinType1 \ndata['BsmtExposure']=data['BsmtExposure'].fillna('NA')\ndata['BsmtCond']=data['BsmtCond'].fillna('NA')\ndata['BsmtQual']=data['BsmtQual'].fillna('NA')\ndata['BsmtFinType2']=data['BsmtFinType2'].fillna('NA')\ndata['BsmtFinType1']=data['BsmtFinType1'].fillna('NA')\n\n#BsmtFinSF1,BsmtFinSF2 \ndata['BsmtFinSF1']=data['BsmtFinSF1'].fillna(0)\ndata['BsmtFinSF2']=data['BsmtFinSF2'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MasVnrType,MasVnrArea\ndata['MasVnrType']=data['MasVnrType'].fillna('NA')\ndata['MasVnrArea']=data['MasVnrArea'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MSZoning \ndata['MSZoning']=data['MSZoning'].fillna(data['MSZoning'].dropna().sort_values().index[0])\n#Utilities\ndata['Utilities']=data['Utilities'].fillna(data['Utilities'].dropna().sort_values().index[0])\n#BsmtFullBath\ndata['BsmtFullBath']=data['BsmtFullBath'].fillna(0)\n\n#Functional\ndata['Functional']=data['Functional'].fillna(data['Functional'].dropna().sort_values().index[0])\n\n#BsmtHalfBath\ndata['BsmtHalfBath']=data['BsmtHalfBath'].fillna(0)\n\n#BsmtUnfSF\ndata['BsmtUnfSF']=data['BsmtUnfSF'].fillna(0)\n#Exterior2nd\ndata['Exterior2nd']=data['Exterior2nd'].fillna('NA')\n\n#Exterior1st\ndata['Exterior1st']=data['Exterior1st'].fillna('NA')\n#TotalBsmtSF\ndata['TotalBsmtSF']=data['TotalBsmtSF'].fillna(0)\n#SaleType\ndata['SaleType']=data['SaleType'].fillna(data['SaleType'].dropna().sort_values().index[0])\n#Electrical\ndata['Electrical']=data['Electrical'].fillna(data['Electrical'].dropna().sort_values().index[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KitchenQual\ndata['KitchenQual']=data['KitchenQual'].fillna(data['KitchenQual'].dropna().sort_values().index[0])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now check any missing value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets check any missing remain\nmissing=data.isnull().sum().sort_values(ascending=False)\nmissing=missing.drop(missing[missing==0].index)\nmissing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see that no missing value in data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 3.Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Feature Engineering is a technique by which we create new features that could potentially aid in predicting our target variable, which in this case, is SalePrice. In this notebook, we will create additional features based on our **Domain Knowledge** of the housing features\n\nBased on the current feature we have, the first additional featuire we can add would be **TotalLot**, which sums up both the LotFrontage and LotArea to identify the total area of land available as lot. We can also calculate the total number of surface area of the house, TotalSF by adding the area from basement and 2nd floor. **TotalBath** can also be used to tell us in total how many bathrooms are there in the house. We can also add all the different types of porches around the house and generalise into a total porch area, **TotalPorch**.\n\n* TotalLot = LotFrontage + LotArea\n* TotalSF = TotalBsmtSF + 2ndFlrSF\n* TotalBath = FullBath + HalfBath\n* TotalPorch = OpenPorchSF + EnclosedPorch + ScreenPorch\n* TotalBsmtFin = BsmtFinSF1 + BsmtFinSF2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#as we know some feature are highly co-related with SalePrice so lets create some feature using these features\ndata['GrLivArea_2']=data['GrLivArea']**2\ndata['GrLivArea_3']=data['GrLivArea']**3\ndata['GrLivArea_4']=data['GrLivArea']**4\n\ndata['TotalBsmtSF_2']=data['TotalBsmtSF']**2\ndata['TotalBsmtSF_3']=data['TotalBsmtSF']**3\ndata['TotalBsmtSF_4']=data['TotalBsmtSF']**4\n\ndata['GarageCars_2']=data['GarageCars']**2\ndata['GarageCars_3']=data['GarageCars']**3\ndata['GarageCars_4']=data['GarageCars']**4\n\ndata['1stFlrSF_2']=data['1stFlrSF']**2\ndata['1stFlrSF_3']=data['1stFlrSF']**3\ndata['1stFlrSF_4']=data['1stFlrSF']**4\n\ndata['GarageArea_2']=data['GarageArea']**2\ndata['GarageArea_3']=data['GarageArea']**3\ndata['GarageArea_4']=data['GarageArea']**4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets add 1stFlrSF and 2ndFlrSF and create new feature floorfeet\ndata['Floorfeet']=data['1stFlrSF']+data['2ndFlrSF']\ndata=data.drop(['1stFlrSF','2ndFlrSF'],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MSSubClass,MSZoning\ndata=pd.get_dummies(data=data,columns=['MSSubClass'],prefix='MSSubClass')\ndata=pd.get_dummies(data=data,columns=['MSZoning'],prefix='MSZoning')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['TotalLot'] = X['LotFrontage'] + X['LotArea']\nX['TotalBsmtFin'] = X['BsmtFinSF1'] + X['BsmtFinSF2']\nX['TotalSF'] = X['TotalBsmtSF'] + X['2ndFlrSF']\nX['TotalBath'] = X['FullBath'] + X['HalfBath']\nX['TotalPorch'] = X['OpenPorchSF'] + X['EnclosedPorch'] + X['ScreenPorch']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Binay Columns\n\nWe also include simple feature engineering by creating binary columns for some features that can indicate the presence(1) / absence(0) of some features of the house","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"colum = ['MasVnrArea','TotalBsmtFin','TotalBsmtSF','2ndFlrSF','WoodDeckSF','TotalPorch']\n\nfor col in colum:\n    col_name = col+'_bin'\n    X[col_name] = X[col].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting Categorical to Numerical\nLastly, because machine learning only learns from data that is numerical in nature, we will convert the remaining categorical columns into one-hot features using the get_dummies() method into numerical columns that is suitable for feeding into our machine learning algorithm.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.get_dummies(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SalePrice Distribution\n> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(\"Before transformation of SalePrice\")\ndist = sns.distplot(train['SalePrice'],norm_hist=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution is skewed to the right, where the tail on the curve’s right-hand side is longer than the tail on the left-hand side, and the mean is greater than the mode. This situation is also called positive skewness.\nHaving a skewed target will affect the overall performance of our machine learning model, thus, one way to alleviate will be to using **log transformation** on skewed target, in our case, the SalePrice to reduce the skewness of the distribution.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(\"After transformation of SalePrice\")\ndist = sns.distplot(np.log(train['SalePrice']),norm_hist=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y[\"SalePrice\"] = np.log(y['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we are satisfied with our final data, we will proceed to the part where we will solve this regression problem - Modeling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4. Modling\n\nThis section will consist of scaling the data for better optimization in our training, and also introducing the varieties of ensembling methods that are used in this notebook for predicting the Housing price. We also try out hyperparameter tuning briefly, as i will be dedicating a new notebook that will explain more in details on the process of Hyperparameter Tuning as well as the mathematical aspect of the ensemble algorithms.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Split into train-validation set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = X.loc[train.index]\ny = y.loc[train.index]\ntest = X.loc[test.index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scaling of Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets import StandardScaler from sklearn for feature scalling\nfrom sklearn.preprocessing import StandardScaler\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets split data using trainrow data and scale data\ncols = x.select_dtypes(np.number).columns\ntransformer = RobustScaler().fit(x[cols])\nx[cols] = transformer.transform(x[cols])\ntest[cols] = transformer.transform(test[cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_correlation = train.select_dtypes(exclude='object').corr()\ncorr = num_correlation.corr()\nprint(corr['SalePrice'].sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create target object and call it y\ny = train.SalePrice\n# Create X\n#features = ['OverallQual','LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF','FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'GrLivArea','GarageCars', 'GarageArea']\nfeaturestop=['OverallQual','TotalBsmtSF', 'YearBuilt','YearRemodAdd','GarageYrBlt','Fireplaces', '1stFlrSF', 'MasVnrArea','FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'GrLivArea','GarageCars', 'GarageArea']\nX = train[featurestop]\ntrain[featurestop]\nsns.heatmap(X.isnull(),yticklabels=False, cbar=False, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Check TestData\n# path to file you will use for predictions\ntest_data_path = '/kaggle/input/home-data-for-ml-course/test.csv'\n\n# read test data file using pandas\ntest_data = pd.read_csv(test_data_path)\n\n# create test_X which comes from test_data but includes only the columns you used for prediction.\n# The list of columns is stored in a variable called features\ntest_X = test_data[featurestop]\n#test_X.dropna(inplace=True)\ntest_X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GarageYrBltmean=X.loc[:,\"GarageYrBlt\"].mean()\nMasVnrAreamean=X.loc[:,\"MasVnrArea\"].mean()\nprint(GarageYrBltmean,MasVnrAreamean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['GarageYrBlt'].fillna(GarageYrBltmean,inplace = True)\nX['MasVnrArea'].fillna(MasVnrAreamean,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Define the model. Set random_state to 1\nrf_model = RandomForestRegressor(random_state=1)\nrf_model.fit(train_X, train_y)\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#working with missing Values\nGarageCarsmean=test_X.loc[:,\"GarageCars\"].mean()\nGarageAreamean=test_X.loc[:,\"GarageArea\"].mean()\nGarageYrBltmean=test_X.loc[:,\"GarageYrBlt\"].mean()\nMasVnrAreamean=test_X.loc[:,\"MasVnrArea\"].mean()\nTotalBsmtSFmean=test_X.loc[:,\"TotalBsmtSF\"].mean()\nprint(GarageYrBltmean,MasVnrAreamean)\nprint(GarageCarsmean,GarageAreamean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X['GarageArea'].fillna(GarageAreamean,inplace = True)\ntest_X['GarageYrBlt'].fillna(GarageYrBltmean,inplace = True)\ntest_X['MasVnrArea'].fillna(MasVnrAreamean,inplace = True)\ntest_X['GarageCars'].fillna(GarageCarsmean,inplace = True)\ntest_X['TotalBsmtSF'].fillna(TotalBsmtSFmean,inplace = True)\ntest_X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model_on_full_data = RandomForestRegressor(random_state=1)\nrf_model_on_full_data.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions which we will submit. \ntest_preds = rf_model_on_full_data.predict(test_X)\n\n# The lines below shows how to save predictions in format used for competition scoring\n# Just uncomment them.\n\n#output = pd.DataFrame({'Id': test_data.Id,\n#                       'SalePrice': test_preds})\n#output.to_csv('submission.csv', index=False)\nrf_model_on_full_data = RandomForestRegressor(random_state=1)\nrf_model_on_full_data.fit(X, y)\n\n# Then in last code cell\n\n\noutput = pd.DataFrame({'Id': test_data.Id,\n                       'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hope you guys have learnt how the whole process of solving a regression problems looks like, understood the importance of data preprocessing and gain insights into the varieties of ensembling algorithms that you can use in future regression problems :)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Please Upvote this notebook if it has helped you in any ways! Thank you:)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}